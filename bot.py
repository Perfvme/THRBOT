import multiprocessing
multiprocessing.set_start_method('spawn', force=True)

from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes
import config
import data_fetcher
import analysis
import gemini_processor
from binance.exceptions import BinanceAPIException
from apscheduler.schedulers.background import BackgroundScheduler
from ml_model import ml
import textwrap
import time
import traceback
import logging
import numpy as np

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler('bot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def start_scheduler():
    """Initialize scheduler with resource monitoring"""
    scheduler = BackgroundScheduler()
    scheduler.add_job(ml.train, 'interval', hours=24)
    scheduler.start()
    logger.info("Scheduler started with daily ML training")
    return scheduler

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Enhanced welcome message with system status"""
    try:
        health_status = "üü¢ Operational" if ml.model else "üü° Initializing"
        await update.message.reply_text(textwrap.dedent(f"""\
            üöÄ Crypto Analysis Bot 3.0 üöÄ
            
            System Status: {health_status}
            ML Model: {'Trained' if ml.model else 'Pending'}
            
            Usage:
            /analyze <coin>  Example: /analyze BTC"""))
    except Exception as e:
        logger.error(f"Start command error: {str(e)}")

async def analyze_coin(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Robust analysis handler with circuit breaker"""
    try:
        if not context.args:
            await update.message.reply_text("‚ùå Please provide a coin symbol. Example: /analyze BTC")
            return

        raw_symbol = context.args[0].upper().strip()
        timeframes = ['5m', '15m', '1h', '4h', '1d']
        timeframe_data = {}

        # Initial symbol check with retry
        max_retries = 3
        for attempt in range(max_retries):
            try:
                df, error = data_fetcher.get_crypto_data(raw_symbol, '5m')
                if error: raise ValueError(error)
                break
            except Exception as e:
                if attempt == max_retries - 1: raise
                logger.warning(f"Data fetch attempt {attempt+1} failed: {str(e)}")
                time.sleep(2 ** attempt)

        # Process timeframes with error isolation
        for tf in timeframes:
            try:
                df, error = data_fetcher.get_crypto_data(raw_symbol, tf)
                if error: raise ValueError(error)
                
                ta = analysis.analyze_data(df, raw_symbol)
                if 'error' in ta: raise ValueError(ta['error'])
                
                # ML Prediction with fallback
                ml_pred = ml.predict({
                    'RSI': ta['rsi'],
                    'EMA_20': ta['ema'],
                    'EMA_50': ta['ema50'],
                    'MACD': ta['macd'],
                    'VWAP': ta['vwap'],
                    'ADX': ta['adx'],
                    'funding_rate': ta.get('funding_rate', 0),
                    'open_interest': ta.get('open_interest', 0),
                    'LIQUIDATION_IMPACT': ta.get('liq_impact', 0)
                })
                
                ta.update({
                    'ml_confidence': ml_pred['confidence'],
                    'ml_uncertainty': ml_pred['uncertainty'],
                    'quant_confidence': min(100, max(0, 0.6*ta['quant_confidence'] + 0.4*ml_pred['confidence']))
                })
                
                timeframe_data[tf] = ta
                
            except Exception as tf_error:
                logger.error(f"Timeframe {tf} analysis failed: {str(tf_error)}")
                continue

        # Generate output
        analysis_text = f"üìä *{raw_symbol} Multi-Timeframe Analysis*\n\n"
        analysis_text += "```\nTF    | Price    | ML Conf | Uncertainty | Q-Conf\n"
        analysis_text += "-----------------------------------------------------\n"
        
        for tf in timeframes:
            ta = timeframe_data.get(tf, {
                'price': 0.0,
                'ml_confidence': 50.0,
                'ml_uncertainty': 100.0,
                'quant_confidence': 50.0,
                'ema50': 0.0
            })
            analysis_text += (
                f"{tf.upper().ljust(4)} "
                f"| ${ta['price']:>7.2f} "
                f"| {ta['ml_confidence']:>6.1f}% "
                f"| ¬±{ta['ml_uncertainty']:>4.1f}% "
                f"| {ta['quant_confidence']:>5.1f}%\n"
            )
        analysis_text += "```\n\n"

        # Key levels with fallback
        try:
            ema50_values = [ta['ema50'] for ta in timeframe_data.values()]
            analysis_text += f"üîë Key Levels:\n‚Ä¢ Support: ${min(ema50_values):.2f}\n‚Ä¢ Resistance: ${max(ema50_values):.2f}\n\n"
        except:
            analysis_text += "üîë Key Levels: Data unavailable\n\n"

        # AI recommendations
        try:
            await update.message.reply_text("üîÑ Generating AI recommendations...")
            recommendations = gemini_processor.get_gemini_analysis(analysis_text)
        except Exception as ai_error:
            recommendations = f"‚ö†Ô∏è AI Analysis Unavailable: {str(ai_error)}"
            logger.error(f"Gemini failed: {str(ai_error)}")

        # Final message
        final_message = textwrap.dedent(f"""\
        üìà Final Analysis for {raw_symbol}:
        {recommendations if "‚ö†Ô∏è" not in recommendations else "‚ö†Ô∏è Partial Analysis:\\n" + recommendations}

        ü§ñ ML Insights:
        - Average Confidence: {np.mean([t.get('ml_confidence',50) for t in timeframe_data.values()]):.1f}%
        - System Health: {'Stable' if ml.model else 'Initializing'}

        ‚ö†Ô∏è Disclaimer: Algorithmic analysis only. Verify with other sources.""")

        await update.message.reply_text(final_message)

    except BinanceAPIException as e:
        await update.message.reply_text(f"‚ùå Exchange Error: {e.message}")
        logger.error(f"Binance API Error: {str(e)}")
    except Exception as e:
        await update.message.reply_text("üî¥ System temporarily unavailable. Please try again later.")
        logger.error(f"Analysis pipeline failed: {str(e)}\n{traceback.format_exc()}")

def main_loop():
    """Self-healing main execution loop"""
    backoff = 1
    max_backoff = 300  # 5 minutes max
    consecutive_errors = 0
    
    while True:
        try:
            # Fresh instance each iteration
            app = ApplicationBuilder().token(config.TELEGRAM_TOKEN).build()
            app.add_handler(CommandHandler("start", start))
            app.add_handler(CommandHandler("analyze", analyze_coin))
            
            scheduler = start_scheduler()
            
            logger.info("üöÄ Starting bot...")
            app.run_polling()
            
            # Reset counters on clean exit
            backoff = 1
            consecutive_errors = 0
            
        except KeyboardInterrupt:
            logger.info("üõë Graceful shutdown initiated")
            break
        except Exception as e:
            consecutive_errors += 1
            logger.critical(f"üí• Critical failure: {str(e)}\n{traceback.format_exc()}")
            
            # Exponential backoff with jitter
            sleep_time = min(backoff * (2 ** consecutive_errors), max_backoff)
            sleep_time *= np.random.uniform(0.5, 1.5)
            
            logger.info(f"‚è≥ Restarting in {sleep_time:.1f}s (errors: {consecutive_errors})...")
            time.sleep(sleep_time)
            
        finally:
            # Cleanup resources
            try:
                if 'scheduler' in locals() and scheduler.running:
                    scheduler.shutdown()
                ml.close_client()
                if 'app' in locals():
                    app.stop()
            except Exception as cleanup_error:
                logger.error(f"Cleanup failed: {str(cleanup_error)}")

if __name__ == '__main__':
    multiprocessing.freeze_support()  # For Windows, or if freezing the script to exe
    logger.info("üöÄ Application starting...")
    
    # Systemd-style supervision
    while True:
        try:
            main_loop()
        except KeyboardInterrupt:
            logger.info("üî¥ Permanent shutdown requested")
            break
        except Exception as fatal_error:
            logger.critical(f"üíÄ Catastrophic failure: {str(fatal_error)}")
            logger.info("üîÅ Attempting cold restart in 60s...")
            time.sleep(60)
